{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f5c1b4",
   "metadata": {},
   "source": [
    "# Diabetes Health Indicators Classification Project\n",
    "\n",
    "**Objective:** Build and compare multiple classification models to predict diabetes using clinical indicators. Handle class imbalance, perform EDA, preprocessing, model training with GridSearchCV, and interpret results.\n",
    "\n",
    "This notebook is structured to guide you through each step with explanations, reasoning, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d31398",
   "metadata": {},
   "source": [
    "## Project Requirements\n",
    "- Load the Kaggle dataset programmatically using `kaggle.json` credentials.\n",
    "- Perform exploratory data analysis (EDA) to understand distributions and missing data.\n",
    "- Preprocess data: imputation, encoding, scaling, and class balancing with SMOTE.\n",
    "- Train binary classifiers: KNN, Logistic Regression, SVM, Decision Tree (covered in class).\n",
    "- Train two additional classifiers: XGBoost and LightGBM.\n",
    "- Use `GridSearchCV` for hyperparameter tuning of each model.\n",
    "- Evaluate using F1 score, confusion matrix, and ROC curve.\n",
    "- Compare models and select the best by F1.\n",
    "- Provide clear explanations and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade64797",
   "metadata": {},
   "source": [
    "## ML Utility Library Analysis\n",
    "We leverage `generic_ml_utils.py` which provides:\n",
    "- **Data Processing**: loading, imputation (`fit_imputer`), encoding (`encode_categorical`), balancing (`balance_classes`).\n",
    "- **Feature Engineering**: datetime encoding, wind direction encoding (not used here), Combine/Polynomial features.\n",
    "- **Model Evaluation**: `rmse`, `accuracy`, `model_performance_df`, `compare_models`, `select_best_model`, plotting functions.\n",
    "- **Modeling**: `get_model`, `train_model`, `tune_model` for GridSearchCV, and `predict`.\n",
    "\n",
    "Each of these maps directly to our workflow steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628750e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install kaggle xgboost lightgbm imbalanced-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab24081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hybridz/.cache/kagglehub/datasets/alexteboul/diabetes-health-indicators-dataset/versions/1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Kaggle config and download dataset\n",
    "import os\n",
    "import kagglehub\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')\n",
    "path = kagglehub.dataset_download(\"alexteboul/diabetes-health-indicators-dataset\")\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26627b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Load the data and inspect basic statistics, distributions, and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380b57e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/hybridz/.cache/kagglehub/datasets/alexteboul/diabetes-health-indicators-dataset/versions/1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df.shape, df.columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/fh1bwkic6lwipb0h7lgvi2yzi19f41fy-dev-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/fh1bwkic6lwipb0h7lgvi2yzi19f41fy-dev-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/fh1bwkic6lwipb0h7lgvi2yzi19f41fy-dev-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/fh1bwkic6lwipb0h7lgvi2yzi19f41fy-dev-env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/fh1bwkic6lwipb0h7lgvi2yzi19f41fy-dev-env/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: '/home/hybridz/.cache/kagglehub/datasets/alexteboul/diabetes-health-indicators-dataset/versions/1'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(path)\n",
    "df.shape, df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad313c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43211b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56575f3",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "1. **Imputation:** Fill missing numerical features using mean strategy.\n",
    "2. **Encoding:** One-hot encode categorical variables.\n",
    "3. **Balancing:** Apply SMOTE to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generic_ml_utils as ml_utils\n",
    "# 1. Impute missing data\n",
    "df_imputed, imputer = ml_utils.fit_imputer(df)\n",
    "# 2. Encode categoricals\n",
    "df_encoded = ml_utils.encode_categorical(df_imputed)\n",
    "# 3. Separate X, y and balance\n",
    "X = df_encoded.drop('Diabetes_binary', axis=1)\n",
    "y = df_encoded['Diabetes_binary']\n",
    "X_res, y_res = ml_utils.balance_classes(X, y, method='smote')\n",
    "X_res.shape, y_res.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0d966",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Split the balanced data into training and testing sets (80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a8275",
   "metadata": {},
   "source": [
    "## Model Training with GridSearchCV\n",
    "Define hyperparameter grids and tune each classifier to maximize F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573335d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'logistic_regression': {'C': [0.1, 1, 10]},\n",
    "    'knn': {'n_neighbors': [3, 5, 7]},\n",
    "    'svm': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'decision_tree': {'max_depth': [None, 5, 10]},\n",
    "    'xgboost_classifier': {'n_estimators': [100, 200], 'max_depth': [3, 5]},\n",
    "    'lightgbm_classifier': {'n_estimators': [100, 200], 'num_leaves': [31, 50]}\n",
    "}\n",
    "from generic_ml_utils import tune_model, model_performance_df\n",
    "search_results = {}\n",
    "estimators = {}\n",
    "results = {}\n",
    "for name, grid in param_grids.items():\n",
    "    print(f'Tuning {name}...')\n",
    "    search = tune_model(\n",
    "        X_train.values, y_train.values, name, grid, cv=5, scoring='f1'\n",
    "    )\n",
    "    search_results[name] = search\n",
    "    best_model = search.best_estimator_\n",
    "    estimators[name] = best_model\n",
    "    y_pred = best_model.predict(X_test.values)\n",
    "    results[name] = model_performance_df(\n",
    "        y_test.values, y_pred, model_type='classification', model_name=name\n",
    "    )\n",
    "print('Tuning complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c07b8",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "Compare model performances and select the best by F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ec620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_ml_utils import compare_models, select_best_model\n",
    "comparison_df = compare_models(results)\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name, best_f1 = select_best_model(results, metric='F1')\n",
    "print(f'Best model: {best_model_name} with F1 = {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d704095",
   "metadata": {},
   "source": [
    "## Visualization of the Best Model\n",
    "- **ROC Curve**\n",
    "- **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e949e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_ml_utils import plot_roc_curve, plot_confusion_matrix\n",
    "best_est = estimators[best_model_name]\n",
    "y_proba = best_est.predict_proba(X_test.values)[:, 1]\n",
    "fig1 = plot_roc_curve(y_test.values, y_proba)\n",
    "fig2 = plot_confusion_matrix(y_test.values, best_est.predict(X_test.values))\n",
    "fig1, fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec3002",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- The best performing model is **{0}** with an F1 score of **{1:.4f}**.\n",
    "- Insights on feature importance and potential improvements:\n",
    "  - Perform advanced feature selection or dimensionality reduction.\n",
    "  - Explore ensemble stacking or voting classifiers.\n",
    "  - Consider calibration of probabilities and threshold optimization.\n",
    "\n",
    "### Next Steps for Presentation\n",
    "- Export key result tables and plots.\n",
    "- Prepare slides summarizing methodology, results, and interpretation.\n",
    "- Keep code notebook available for Q&A during defense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
