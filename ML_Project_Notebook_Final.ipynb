{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f5c1b4",
   "metadata": {},
   "source": [
    "# Diabetes Health Indicators Classification Project\n",
    "\n",
    "**Objective:** Build and compare multiple classification models to predict diabetes using clinical indicators. Handle class imbalance, perform EDA, preprocessing, model training with GridSearchCV, and interpret results.\n",
    "\n",
    "This notebook is structured to guide you through each step with explanations, reasoning, and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d31398",
   "metadata": {},
   "source": [
    "## Project Requirements\n",
    "- Load the Kaggle dataset programmatically using `kaggle.json` credentials.\n",
    "- Perform exploratory data analysis (EDA) to understand distributions and missing data.\n",
    "- Preprocess data: imputation, encoding, scaling, and class balancing with SMOTE.\n",
    "- Train binary classifiers: KNN, Logistic Regression, SVM, Decision Tree (covered in class).\n",
    "- Train two additional classifiers: XGBoost and LightGBM.\n",
    "- Use `GridSearchCV` for hyperparameter tuning of each model.\n",
    "- Evaluate using F1 score, confusion matrix, and ROC curve.\n",
    "- Compare models and select the best by F1.\n",
    "- Provide clear explanations and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade64797",
   "metadata": {},
   "source": [
    "## ML Utility Library Analysis\n",
    "We leverage `generic_ml_utils.py` which provides:\n",
    "- **Data Processing**: loading, imputation (`fit_imputer`), encoding (`encode_categorical`), balancing (`balance_classes`).\n",
    "- **Feature Engineering**: datetime encoding, wind direction encoding (not used here), Combine/Polynomial features.\n",
    "- **Model Evaluation**: `rmse`, `accuracy`, `model_performance_df`, `compare_models`, `select_best_model`, plotting functions.\n",
    "- **Modeling**: `get_model`, `train_model`, `tune_model` for GridSearchCV, and `predict`.\n",
    "\n",
    "Each of these maps directly to our workflow steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install kaggle xgboost lightgbm imbalanced-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab24081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Kaggle config and download dataset\n",
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')\n",
    "!kaggle datasets download -d plamen2/diabetes-health-indicators-dataset -p data --unzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26627b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Load the data and inspect basic statistics, distributions, and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/diabetes_health_indicators.csv')\n",
    "df.shape, df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad313c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43211b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56575f3",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "1. **Imputation:** Fill missing numerical features using mean strategy.\n",
    "2. **Encoding:** One-hot encode categorical variables.\n",
    "3. **Balancing:** Apply SMOTE to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generic_ml_utils as ml_utils\n",
    "# 1. Impute missing data\n",
    "df_imputed, imputer = ml_utils.fit_imputer(df)\n",
    "# 2. Encode categoricals\n",
    "df_encoded = ml_utils.encode_categorical(df_imputed)\n",
    "# 3. Separate X, y and balance\n",
    "X = df_encoded.drop('Diabetes_binary', axis=1)\n",
    "y = df_encoded['Diabetes_binary']\n",
    "X_res, y_res = ml_utils.balance_classes(X, y, method='smote')\n",
    "X_res.shape, y_res.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0d966",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Split the balanced data into training and testing sets (80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a8275",
   "metadata": {},
   "source": [
    "## Model Training with GridSearchCV\n",
    "Define hyperparameter grids and tune each classifier to maximize F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573335d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'logistic_regression': {'C': [0.1, 1, 10]},\n",
    "    'knn': {'n_neighbors': [3, 5, 7]},\n",
    "    'svm': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'decision_tree': {'max_depth': [None, 5, 10]},\n",
    "    'xgboost_classifier': {'n_estimators': [100, 200], 'max_depth': [3, 5]},\n",
    "    'lightgbm_classifier': {'n_estimators': [100, 200], 'num_leaves': [31, 50]}\n",
    "}\n",
    "from generic_ml_utils import tune_model, model_performance_df\n",
    "search_results = {}\n",
    "estimators = {}\n",
    "results = {}\n",
    "for name, grid in param_grids.items():\n",
    "    print(f'Tuning {name}...')\n",
    "    search = tune_model(\n",
    "        X_train.values, y_train.values, name, grid, cv=5, scoring='f1'\n",
    "    )\n",
    "    search_results[name] = search\n",
    "    best_model = search.best_estimator_\n",
    "    estimators[name] = best_model\n",
    "    y_pred = best_model.predict(X_test.values)\n",
    "    results[name] = model_performance_df(\n",
    "        y_test.values, y_pred, model_type='classification', model_name=name\n",
    "    )\n",
    "print('Tuning complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c07b8",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "Compare model performances and select the best by F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ec620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_ml_utils import compare_models, select_best_model\n",
    "comparison_df = compare_models(results)\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name, best_f1 = select_best_model(results, metric='F1')\n",
    "print(f'Best model: {best_model_name} with F1 = {best_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d704095",
   "metadata": {},
   "source": [
    "## Visualization of the Best Model\n",
    "- **ROC Curve**\n",
    "- **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e949e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_ml_utils import plot_roc_curve, plot_confusion_matrix\n",
    "best_est = estimators[best_model_name]\n",
    "y_proba = best_est.predict_proba(X_test.values)[:, 1]\n",
    "fig1 = plot_roc_curve(y_test.values, y_proba)\n",
    "fig2 = plot_confusion_matrix(y_test.values, best_est.predict(X_test.values))\n",
    "fig1, fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec3002",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- The best performing model is **{0}** with an F1 score of **{1:.4f}**.\n",
    "- Insights on feature importance and potential improvements:\n",
    "  - Perform advanced feature selection or dimensionality reduction.\n",
    "  - Explore ensemble stacking or voting classifiers.\n",
    "  - Consider calibration of probabilities and threshold optimization.\n",
    "\n",
    "### Next Steps for Presentation\n",
    "- Export key result tables and plots.\n",
    "- Prepare slides summarizing methodology, results, and interpretation.\n",
    "- Keep code notebook available for Q&A during defense."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
